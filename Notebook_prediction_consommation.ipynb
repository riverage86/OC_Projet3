{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aaa3b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import kernel_ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bed1bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('features.csv',  engine = 'python',  on_bad_lines = 'skip', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a7d7a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "67348ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SiteEUIWN(kBtu/sf)</th>\n",
       "      <th>SteamUse(kBtu)</th>\n",
       "      <th>Electricity(kBtu)</th>\n",
       "      <th>NaturalGas(kBtu)</th>\n",
       "      <th>GHGEmissionsIntensity</th>\n",
       "      <th>Type_Distribution Center</th>\n",
       "      <th>Type_Hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighbor_NORTHEAST</th>\n",
       "      <th>Neighbor_NORTHWEST</th>\n",
       "      <th>Neighbor_North</th>\n",
       "      <th>Neighbor_Northwest</th>\n",
       "      <th>Neighbor_SOUTHEAST</th>\n",
       "      <th>Neighbor_SOUTHWEST</th>\n",
       "      <th>Built_1900-1945</th>\n",
       "      <th>Built_1946-1970</th>\n",
       "      <th>Built_1971-1990</th>\n",
       "      <th>Built_1991-2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [NumberofFloors, ENERGYSTARScore, SiteEUI(kBtu/sf), SiteEUIWN(kBtu/sf), SteamUse(kBtu), Electricity(kBtu), NaturalGas(kBtu), GHGEmissionsIntensity, Type_Distribution Center, Type_Hospital, Type_Hotel, Type_K-12 School, Type_Laboratory, Type_Large Office, Type_Low-Rise Multifamily, Type_Medical Office, Type_Mixed Use Property, Type_Other, Type_Refrigerated Warehouse, Type_Residence Hall, Type_Restaurant, Type_Retail Store, Type_Self-Storage Facility, Type_Senior Care Community, Type_Small- and Mid-Sized Office, Type_Supermarket / Grocery Store, Type_University, Type_Warehouse, Type_Worship Facility, Neighbor_BALLARD, Neighbor_Ballard, Neighbor_CENTRAL, Neighbor_Central, Neighbor_DELRIDGE, Neighbor_DELRIDGE NEIGHBORHOODS, Neighbor_DOWNTOWN, Neighbor_Delridge, Neighbor_EAST, Neighbor_GREATER DUWAMISH, Neighbor_LAKE UNION, Neighbor_MAGNOLIA / QUEEN ANNE, Neighbor_NORTH, Neighbor_NORTHEAST, Neighbor_NORTHWEST, Neighbor_North, Neighbor_Northwest, Neighbor_SOUTHEAST, Neighbor_SOUTHWEST, Built_1900-1945, Built_1946-1970, Built_1971-1990, Built_1991-2015]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 52 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b8e735c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d9cbdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberofFloors                      0\n",
      "ENERGYSTARScore                     0\n",
      "SiteEUI(kBtu/sf)                    0\n",
      "SiteEUIWN(kBtu/sf)                  0\n",
      "SteamUse(kBtu)                      0\n",
      "Electricity(kBtu)                   0\n",
      "NaturalGas(kBtu)                    0\n",
      "GHGEmissionsIntensity               0\n",
      "Type_Distribution Center            0\n",
      "Type_Hospital                       0\n",
      "Type_Hotel                          0\n",
      "Type_K-12 School                    0\n",
      "Type_Laboratory                     0\n",
      "Type_Large Office                   0\n",
      "Type_Low-Rise Multifamily           0\n",
      "Type_Medical Office                 0\n",
      "Type_Mixed Use Property             0\n",
      "Type_Other                          0\n",
      "Type_Refrigerated Warehouse         0\n",
      "Type_Residence Hall                 0\n",
      "Type_Restaurant                     0\n",
      "Type_Retail Store                   0\n",
      "Type_Self-Storage Facility          0\n",
      "Type_Senior Care Community          0\n",
      "Type_Small- and Mid-Sized Office    0\n",
      "Type_Supermarket / Grocery Store    0\n",
      "Type_University                     0\n",
      "Type_Warehouse                      0\n",
      "Type_Worship Facility               0\n",
      "Neighbor_BALLARD                    0\n",
      "Neighbor_Ballard                    0\n",
      "Neighbor_CENTRAL                    0\n",
      "Neighbor_Central                    0\n",
      "Neighbor_DELRIDGE                   0\n",
      "Neighbor_DELRIDGE NEIGHBORHOODS     0\n",
      "Neighbor_DOWNTOWN                   0\n",
      "Neighbor_Delridge                   0\n",
      "Neighbor_EAST                       0\n",
      "Neighbor_GREATER DUWAMISH           0\n",
      "Neighbor_LAKE UNION                 0\n",
      "Neighbor_MAGNOLIA / QUEEN ANNE      0\n",
      "Neighbor_NORTH                      0\n",
      "Neighbor_NORTHEAST                  0\n",
      "Neighbor_NORTHWEST                  0\n",
      "Neighbor_North                      0\n",
      "Neighbor_Northwest                  0\n",
      "Neighbor_SOUTHEAST                  0\n",
      "Neighbor_SOUTHWEST                  0\n",
      "Built_1900-1945                     0\n",
      "Built_1946-1970                     0\n",
      "Built_1971-1990                     0\n",
      "Built_1991-2015                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dc4ab4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1534, 52)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e41ee",
   "metadata": {},
   "source": [
    "# 3 Prédiction Consomation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be85ae",
   "metadata": {},
   "source": [
    "## 3.2. préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d460616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features numériques utilisées \n",
    "X_cols_num = ['NumberofFloors', 'ENERGYSTARScore', 'SiteEUIWN(kBtu/sf)', 'SteamUse(kBtu)', 'Electricity(kBtu)', 'NaturalGas(kBtu)']\n",
    "len(X_cols_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04bf1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_cols_remove = ['GHGEmissionsIntensity', 'GHGEmissionsIntensity_log', 'SiteEUI(kBtu/sf)_log', 'SiteEUI(kBtu/sf)' ]\n",
    "X_cols_remove = ['GHGEmissionsIntensity', 'SiteEUI(kBtu/sf)' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8bd70178",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(X_cols_remove, axis = 1).values\n",
    "y = data['SiteEUI(kBtu/sf)'].values\n",
    "#y = data['SiteEUI(kBtu/sf)_log'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "957ec9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation de train et test \n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "94ae79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation seulement des variables numériques\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num = X_train[:, :len(X_cols_num)]\n",
    "X_train_cat = X_train[:, len(X_cols_num):]\n",
    "X_train_num_std = scaler.fit_transform(X_train_num)\n",
    "X_train_std = np.concatenate((X_train_num_std, X_train_cat), axis=1)\n",
    "\n",
    "X_test_num = X_test[:, :len(X_cols_num)]\n",
    "X_test_cat = X_test[:, len(X_cols_num):]\n",
    "X_test_num_std = scaler.fit_transform(X_test_num)\n",
    "X_test_std = np.concatenate((X_test_num_std, X_test_cat), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9e679c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"MSE : {:.2f}\".format(mse))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE: {:.2f}\".format(rmse))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"R2 : {:.2f}\".format(r2))\n",
    "    return mse, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac5ff5",
   "metadata": {},
   "source": [
    "## 3.3 Choix de modèle et noyau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa6825",
   "metadata": {},
   "source": [
    "### 3.3.1 Baseline avec regression linéaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6ff1874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 498065661910381101056.00\n",
      "RMSE: 22317384746.21\n",
      "R2 : -119872645058118032.00\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred = model.predict(X_test_std)\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "11abbbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 4199.78\n",
      "RMSE: 64.81\n",
      "R2 : -0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "dummy_regressor = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Entraîner le dummy regressor sur les données d'entraînement\n",
    "dummy_regressor.fit(X_train_std, y_train)\n",
    "\n",
    "# Prédire les valeurs cibles pour les données de test\n",
    "y_pred = dummy_regressor.predict(X_test_std)\n",
    "\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27543857",
   "metadata": {},
   "source": [
    "### 3.3.2   Modèle  avec  KernelRidgeRegression à  noyau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d0872eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 239.94\n",
      "RMSE: 15.49\n",
      "R2 : 0.94\n"
     ]
    }
   ],
   "source": [
    "# Noyau linéaire \n",
    "model = KernelRidge(alpha=1, kernel='linear')\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred = model.predict(X_test_std)\n",
    "mse, rmse, r2 = performance(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "89ad298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 202.64\n",
      "RMSE: 14.24\n",
      "R2 : 0.95\n"
     ]
    }
   ],
   "source": [
    "# avec Noyau non linéaire gaussien rbf \n",
    "model = KernelRidge(alpha=1, kernel='rbf', gamma=0.01)\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred = model.predict(X_test_std)\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddae1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaaf62ac",
   "metadata": {},
   "source": [
    "Recheche des hyper paramètres par grilles de alpha, gamma et noyau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48b7b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres :  {'alpha': 0.0031622776601683794, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "Meilleure performance :  0.5485871521614861\n",
      "MSE : 0.35\n",
      "RMSE: 0.59\n",
      "R2 : 0.48\n"
     ]
    }
   ],
   "source": [
    "# Create a KRR model  ( Running time = 10s)\n",
    "kr = KernelRidge()\n",
    "\n",
    "# Définir la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-4, 2, 5),\n",
    "    'gamma': np.logspace(-4, 2, 5),\n",
    "    'kernel': ['linear', 'polynomial', 'rbf']\n",
    "}\n",
    "\n",
    "# Effectuer la recherche d'hyperparamètres par validation croisée et recherche en grille\n",
    "grid_search = GridSearchCV(estimator=kr, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres trouvés et leur performance\n",
    "print(\"Meilleurs paramètres : \", grid_search.best_params_)\n",
    "print(\"Meilleure performance : \", np.sqrt(-grid_search.best_score_))\n",
    "\n",
    "# Utiliser les meilleurs paramètres pour ajuster le modèle final\n",
    "kr_final = grid_search.best_estimator_\n",
    "\n",
    "# prédire sur le jeu de test avec le modèle sélectionné \n",
    "y_pred = kr_final.predict(X_test_std)\n",
    "\n",
    "# calculer les performance \n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45288768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51c70632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.27\n",
      "RMSE: 0.52\n",
      "R2 : 0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Définition du modèle SVM\n",
    "svm_model = SVR(kernel='rbf', C=1)\n",
    "\n",
    "# Entraînement du modèle SVM\n",
    "svm_model.fit(X_train_std, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = svm_model.predict(X_test_std)\n",
    "\n",
    "# Calcul de la performance du modèle\n",
    "# calculer les performance \n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eab9b0",
   "metadata": {},
   "source": [
    "### 3.3.3  Modèle ensembliste parallèle : Random forest Regression\n",
    "Ramdon forest est adapté pour prédiction par regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1021dec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.22\n",
      "RMSE: 0.47\n",
      "R2 : 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Créer un modèle de forêt aléatoire\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Former le modèle sur les données non normalisées, car ensembliste n'est pas sensible \n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# prédire sur le jeu de test avec le modèle sélectionné \n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# calculer les performance \n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39108b",
   "metadata": {},
   "source": [
    "Recheche de hyper paramètres pour RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d22cf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres :  {'criterion': 'mse', 'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Meilleure performance :  0.4181109482885112\n",
      "MSE : 0.22\n",
      "RMSE: 0.47\n",
      "R2 : 0.68\n"
     ]
    }
   ],
   "source": [
    "# (Running time = 36min  , with CPU 90%)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir le modèle de Random Forest Regression\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Définir la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion': ['mse', 'mae']\n",
    "}\n",
    "\n",
    "# Effectuer la recherche d'hyperparamètres par validation croisée et recherche en grille\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres trouvés et leur performance\n",
    "print(\"Meilleurs paramètres : \", grid_search.best_params_)\n",
    "print(\"Meilleure performance : \", np.sqrt(-grid_search.best_score_))\n",
    "\n",
    "# Utiliser les meilleurs paramètres pour ajuster le modèle final\n",
    "rf_final = grid_search.best_estimator_\n",
    "#rf_final = RandomForestRegressor(**grid_search.best_params_)\n",
    "#rf_final.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des valeurs de la variable cible pour les données de test\n",
    "y_pred = rf_final.predict(X_test)\n",
    "\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc40c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f4f5db4",
   "metadata": {},
   "source": [
    "### 3.3.4. Ensembliste parallèle: Bagging Regression avec Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6dcc0a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.24\n",
      "RMSE: 0.49\n",
      "R2 : 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Division des données en ensembles d'apprentissage et de test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Construction du modèle de bagging avec 10 arbres de décision\n",
    "bagging = BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n",
    "                            n_estimators=10, random_state=42)\n",
    "\n",
    "# Apprentissage du modèle sur les données d'apprentissage\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des valeurs de la variable cible pour les données de test\n",
    "y_pred = bagging.predict(X_test)\n",
    "\n",
    "# Evaluation de la précision des prévisions\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper paramètres pour Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50040769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :  {'n_estimators': 500}\n",
      "Score R2 :  0.7456450837318108\n",
      "MSE : 0.22\n",
      "RMSE: 0.47\n",
      "R2 : 0.67\n"
     ]
    }
   ],
   "source": [
    "# Définir le modèle de base  (running time = 10s)\n",
    "base_model = DecisionTreeRegressor()\n",
    "\n",
    "# Définir le modèle Bagging avec GridSearchCV\n",
    "bagging_model = GridSearchCV(BaggingRegressor(base_estimator=base_model),\n",
    "                             param_grid={'n_estimators': [10, 100, 500]},\n",
    "                             cv=5)\n",
    "\n",
    "# Adapter le modèle sur les données d'entraînement\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtenir les meilleurs hyper-paramètres et le score R2 correspondant\n",
    "print(\"Meilleurs hyper-paramètres : \", bagging_model.best_params_)\n",
    "print(\"Score R2 : \", bagging_model.best_score_)\n",
    "\n",
    "# Utiliser les meilleurs paramètres pour ajuster le modèle final\n",
    "bagging_final = bagging_model.best_estimator_\n",
    "#bagging_final = RandomForestRegressor(**bagging_model.best_params_)\n",
    "#bagging_final.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des valeurs de la variable cible pour les données de test\n",
    "y_pred = bagging_final.predict(X_test)\n",
    "\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846fe8f",
   "metadata": {},
   "source": [
    "### 3.3.5 Ensembliste séquentielle : GBoostRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6993b1e1",
   "metadata": {},
   "source": [
    "GBoost Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6271cedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.19\n",
      "RMSE: 0.43\n",
      "R2 : 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Division des données en ensembles d'apprentissage et de test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialiser le modèle Gradient Boosting Regressor\n",
    "gb_reg = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble de données d'entraînement\n",
    "gb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les valeurs de sortie sur l'ensemble de données de test\n",
    "y_pred = gb_reg.predict(X_test)\n",
    "\n",
    "# Calculer l'erreur quadratique moyenne (MSE) du modèle\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c53e21",
   "metadata": {},
   "source": [
    "Super parametres pour GBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea43b269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :  {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 200, 'subsample': 0.5}\n",
      "Score R2 :  0.7869810962914132\n",
      "MSE : 0.18\n",
      "RMSE: 0.42\n",
      "R2 : 0.73\n"
     ]
    }
   ],
   "source": [
    "# Définir le modèle GBoostRegression avec GridSearchCV   (running time = 10 min , CPU at 30%)\n",
    "gboost_model = GridSearchCV(GradientBoostingRegressor(),\n",
    "                            param_grid={'n_estimators': [50, 100, 200],\n",
    "                                        'max_depth': [2, 4, 6],\n",
    "                                        'learning_rate': [0.01, 0.1, 1],\n",
    "                                        'subsample': [0.5, 0.8, 1.0],\n",
    "                                        'loss': ['ls', 'lad', 'huber']},\n",
    "                            cv=5)\n",
    "\n",
    "# Adapter le modèle sur les données d'entraînement\n",
    "gboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtenir les meilleurs hyper-paramètres et le score R2 correspondant\n",
    "print(\"Meilleurs hyper-paramètres : \", gboost_model.best_params_)\n",
    "print(\"Score R2 : \", gboost_model.best_score_)\n",
    "\n",
    "# Utiliser les meilleurs paramètres pour ajuster le modèle final\n",
    "gboost_final = gboost_model.best_estimator_\n",
    "#gboost_final = GradientBoostingRegressor(**gboost_model.best_params_)\n",
    "#gboost_final.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des valeurs de la variable cible pour les données de test\n",
    "y_pred = gboost_final.predict(X_test)\n",
    "\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a292b9",
   "metadata": {},
   "source": [
    "### 3.3.6 Arbre de décision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf89a035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.41\n",
      "RMSE: 0.64\n",
      "R2 : 0.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# création d'un objet d'arbre de décision de régression\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# entraînement de l'arbre de décision sur les données d'entraînement\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# prédiction des résultats de la variable dépendante sur les données de test\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculer l'erreur quadratique moyenne (MSE) du modèle\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un objet d'arbre de décision de régression  ()\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# définition de la grille de recherche\n",
    "param_grid = {'max_depth': [2, 4, 6, 8],\n",
    "              'min_samples_split': [2, 4, 6, 8],\n",
    "              'min_samples_leaf': [1, 2, 4, 6]}\n",
    "\n",
    "# création d'un objet GridSearchCV pour la recherche sur grille\n",
    "grid_search = GridSearchCV(regressor, param_grid=param_grid, cv=5)\n",
    "\n",
    "# entraînement du modèle avec la recherche sur grille\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# affichage des meilleurs hyperparamètres\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Utiliser les meilleurs paramètres pour ajuster le modèle final\n",
    "grid_final = grid_search.best_estimator_\n",
    "\n",
    "# Prédiction des valeurs de la variable cible pour les données de test\n",
    "y_pred = grid_final.predict(X_test)\n",
    "\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae953b8f",
   "metadata": {},
   "source": [
    "### 3.3.6  Bagging avec plusieurs modèles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa1fd0d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21772\\2040461848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Fit the bagging ensemble to the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mbagging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Evaluate the performance of the bagging ensemble on the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         )\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_seeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         all_results = Parallel(\n\u001b[0m\u001b[0;32m    395\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mbootstrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mbootstrap_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbootstrap_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0msupport_sample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhas_fit_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sample_weight\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msupport_sample_weight\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The base estimator doesn't support sample weight\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mhas_fit_parameter\u001b[1;34m(estimator, parameter)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m     \"\"\"\n\u001b[1;32m-> 1089\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparameter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "# Create base models\n",
    "\n",
    "model2 = LinearRegression()\n",
    "model1 = KernelRidge(alpha=0.1, kernel='rbf', gamma=0.1)\n",
    "\n",
    "# Create an ensemble of models using bagging\n",
    "bagging = BaggingRegressor(base_estimator=[model1, model2], n_estimators=10, random_state=42)\n",
    "\n",
    "# Fit the bagging ensemble to the training data\n",
    "bagging.fit(X_train_std, y_train)\n",
    "\n",
    "# Evaluate the performance of the bagging ensemble on the test data\n",
    "y_pred = bagging.predict(X_test_std)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "mse, rmse, r2 = performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e10ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7b50c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eac0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f63890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1cc28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9873630d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ecf6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55bd77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345a7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6758ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c9e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e4182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f463f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87f356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
